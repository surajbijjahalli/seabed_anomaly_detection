#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Evaluate trained models and the loss metrics during training
Created on Mon Jul  4 15:37:38 2022

@author: surajb
"""

#%% Import libraries
import matplotlib.pyplot as plt
import numpy as np
import glob
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from random import randint


import torch
import torch.nn as nn
import torch.nn.functional as F

from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils


#%% Read in train and validation loss files

val_loss = pd.read_csv("final_model.ptValidation_Loss.csv",header=None)
train_loss = pd.read_csv("final_model.ptTraining_Loss.csv",header=None)



#%% Plot loss metrics

plt.figure()


plt.plot(val_loss,label='Validation loss')
plt.plot(train_loss[2:],label='Training loss')
plt.legend()
plt.grid()



#%% Grab paths to training images

#train_data_path = '/media/surajb/Extreme SSD/marine_dataset_Jervis_2021/r20210407_061916_NG106_hyams_depth_gated_target/raw_targetless_imgs/alp/converted_images'


# train_data_path = '/home/surajb/marine_anomaly_detection/dataset_split/train/data'
# test_data_path = '/home/surajb/marine_anomaly_detection/dataset_split/test/data'
# val_data_path = '/home/surajb/marine_anomaly_detection/dataset_split/val/data'

train_data_path = '../dataset_split/train/data'
test_data_path = '../dataset_split/test/data'
val_data_path = '../dataset_split/val/data'

# Empty list to store paths to images
train_image_paths = []
test_image_paths = []
val_image_paths = []

# Grab paths to images in train folder
for data_path in glob.glob(train_data_path + '/*'):
    
    train_image_paths.append(data_path)
    
train_image_paths = list(train_image_paths)

# Grab paths to images in test folder
for data_path in glob.glob(test_data_path + '/*'):
    
    test_image_paths.append(data_path)
    
test_image_paths = list(test_image_paths)


# Grab paths to images in validation folder
for data_path in glob.glob(val_data_path + '/*'):
    
    val_image_paths.append(data_path)
    
val_image_paths = list(val_image_paths)
# THIS IS WRONG - SHOULD BE VAL IMAGE PATHS

#%% Import custom classes and define transform


# the dataset we created in Notebook 1 is copied in the helper file `data_load.py`
from data_load import MarineBenthicDataset, visualize_output_loader,visualize_raw_data_loader, encoder_sample_output,visualize_vae_output_eval
# the transforms we defined in Notebook 1 are in the helper file `data_load.py`
from data_load import RescaleCustom, RandomCropCustom, NormalizeNew, ToTensorCustom, RandomRotateCustom, RandomHorizontalFlip,RandomVerticalFlip,ColorJitter

from models_2 import vae_loss, VariationalAutoencoder

# Define data transforms for training, validation and testing 
# train_transform = transforms.Compose([RandomCropCustom(64),ToTensorCustom(),RandomHorizontalFlip(),RandomVerticalFlip()])
# valid_transform = transforms.Compose([RandomCropCustom(64),ToTensorCustom()])

train_transform = transforms.Compose([RescaleCustom(64), ToTensorCustom(),RandomHorizontalFlip(),RandomVerticalFlip()])
valid_transform = transforms.Compose([RescaleCustom(64),ToTensorCustom()])

test_transform  = transforms.Compose([RescaleCustom(64),ToTensorCustom()])


#%% Define function for creating dataset and dataloaders

def create_datasets(batch_size, train_image_paths = train_image_paths,test_image_paths=test_image_paths,val_image_paths=val_image_paths,
                    train_transform=train_transform,test_transform=test_transform,valid_transform=valid_transform):

    #Raw dataset
    raw_dataset = MarineBenthicDataset(train_image_paths)
                    
    # create datasets for training, validation and testing. 
    test_dataset = MarineBenthicDataset(test_image_paths,transform=test_transform)

    # create new training dataset for each epoch
    train_dataset = MarineBenthicDataset(train_image_paths,transform=train_transform)
    
    # create new valid dataset for each epoch
    valid_dataset = MarineBenthicDataset(val_image_paths,transform=valid_transform)
            
        
      
    
    # load training data in batches
    train_loader = DataLoader(train_dataset, 
                              batch_size=batch_size,
                              shuffle=True, 
                              num_workers=0)
    
    # load validation data in batches
    valid_loader = DataLoader(valid_dataset,batch_size=batch_size,shuffle=True,num_workers=0)
    
    # load test data in batches
    test_loader = DataLoader(test_dataset, 
                             batch_size=1,
                             shuffle=True,  
                             num_workers=0)
    
    raw_loader = DataLoader(raw_dataset, 
                             batch_size=batch_size,
                             shuffle=True,  
                             num_workers=0)
    
    return train_loader, test_loader, valid_loader,train_dataset,test_dataset,valid_dataset,raw_dataset,raw_loader





#%% Create datasets and dataloaders
batch_size = 32
JB_train_loader,JB_test_loader,JB_val_loader,JB_train_dataset,JB_test_dataset,JB_valid_dataset,raw_dataset,raw_loader = create_datasets(batch_size=batch_size)






#%% Load model
vae = VariationalAutoencoder()
vae.load_state_dict(torch.load('saved_models/final_model.pt',map_location=('cpu')))

vae.eval()

#%% iterate through data and visualize

# Get a random sample
random_index = int(np.random.random()*len(JB_test_dataset))
test_sample = JB_test_dataset[random_index]

test_sample_image = test_sample['image']
test_sample_image = torch.unsqueeze(test_sample_image,0)

# # forward pass the images through the network

image_recon,mu_z,log_var_z = vae(test_sample_image)
        
# # # Calculate loss
total_loss,recon_loss,kl_loss = vae_loss(image_recon, test_sample_image, mu_z, log_var_z)
print('Total loss: ',total_loss.item())
print('Reconstruction loss: ',recon_loss.item())
print('KL divergence: ',kl_loss.item())

visualize_vae_output_eval(test_sample_image, image_recon,total_loss,recon_loss,kl_loss)


# fig,axs = plt.subplots(1,2,figsize=(15,5))
# plt.suptitle('Model output')

# #loop through rows
# for i in range(batch_size):
#     # axs[0,i].imshow(((orig_plot[:,:,:,i]+np.array([0.485,0.456,0.406]))*np.array([0.229,0.224,0.225])))
#     # axs[1,i].imshow(((recon_plot[:,:,:,i]+np.array([0.485,0.456,0.406]))*np.array([0.229,0.224,0.225])))
    
#     axs[0,1].imshow(orig_plot[:,:,:,i])
#     axs[1,i].imshow(recon_plot[:,:,:,i])
#     # axs[1,i].title(total_loss[i].item)


# plt.show()


# for batch_i, data in enumerate(JB_test_loader):
    
#     if batch_i==len(JB_test_loader):
#         break
#     else:
#         # get the input images in each batch and their corresponding names
#         images = data['image']
#         name = data['name']
        
#        # images = images.to(device)
        
#         # forward pass the images through the network
    
#         image_recon,mu_z,log_var_z = vae(images)
        
#         # Calculate loss
#         total_loss,recon_loss,kl_loss = vae_loss(image_recon, images, mu_z, log_var_z)
        
    
#         visualize_vae_output_eval(images, image_recon,total_loss,recon_loss,kl_loss)
    
    
    